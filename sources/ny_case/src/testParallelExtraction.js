#!/usr/bin/env node

/**
 * Test script for parallel keyword extraction with duplicate prevention
 * 
 * Usage:
 *   node testParallelExtraction.js [batch_size] [concurrency]
 * 
 * Examples:
 *   node testParallelExtraction.js 10 3    # Process 10 opinions with 3 workers
 *   node testParallelExtraction.js 20 5    # Process 20 opinions with 5 workers
 */

import { Client } from 'pg';

const CONFIG = {
  dbUrl: 'postgresql://localhost/ny_court_of_appeals'
};

async function testParallelProcessing() {
  console.log('ðŸ§ª Testing Parallel Keyword Extraction with Duplicate Prevention');
  console.log('================================================================\n');

  const batchSize = parseInt(process.argv[2]) || 10;
  const concurrency = parseInt(process.argv[3]) || 3;
  
  console.log(`ðŸ“‹ Test Configuration:`);
  console.log(`   â€¢ Batch Size: ${batchSize} opinions`);
  console.log(`   â€¢ Concurrency: ${concurrency} workers`);
  console.log(`   â€¢ Duplicate Prevention: Enabled\n`);

  const pg = new Client({ connectionString: CONFIG.dbUrl });
  await pg.connect();

  try {
    // Check current state of keyword extraction
    console.log('ðŸ“Š Current Database State:');
    
    const totalOpinions = await pg.query(`
      SELECT COUNT(*) as count 
      FROM opinions o 
      WHERE o.binding_type IN ('015unanimous', '010combined', '020lead')
    `);
    
    const opinionsWithKeywords = await pg.query(`
      SELECT COUNT(DISTINCT ok.opinion_id) as count
      FROM opinion_keywords ok
      JOIN opinions o ON ok.opinion_id = o.id
      WHERE o.binding_type IN ('015unanimous', '010combined', '020lead')
    `);
    
    const opinionsWithoutKeywords = await pg.query(`
      SELECT COUNT(*) as count
      FROM opinions o
      LEFT JOIN opinion_keywords ok ON o.id = ok.opinion_id
      WHERE o.binding_type IN ('015unanimous', '010combined', '020lead')
        AND ok.opinion_id IS NULL
    `);
    
    console.log(`   â€¢ Total binding opinions: ${totalOpinions.rows[0].count}`);
    console.log(`   â€¢ Opinions with keywords: ${opinionsWithKeywords.rows[0].count}`);
    console.log(`   â€¢ Opinions without keywords: ${opinionsWithoutKeywords.rows[0].count}`);
    
    // Test duplicate prevention by trying to process some opinions that already have keywords
    console.log('\nðŸ” Testing Duplicate Prevention:');
    
    const existingKeywordOpinions = await pg.query(`
      SELECT DISTINCT o.id as opinion_id, c.case_name
      FROM opinions o
      JOIN cases c ON o.case_id = c.id
      JOIN opinion_keywords ok ON o.id = ok.opinion_id
      WHERE o.binding_type IN ('015unanimous', '010combined', '020lead')
      LIMIT 3
    `);
    
    if (existingKeywordOpinions.rows.length > 0) {
      console.log(`   Found ${existingKeywordOpinions.rows.length} opinions that already have keywords:`);
      existingKeywordOpinions.rows.forEach(row => {
        console.log(`   â€¢ Opinion ${row.opinion_id}: ${row.case_name.substring(0, 60)}...`);
      });
    } else {
      console.log('   No opinions with existing keywords found for duplicate testing');
    }
    
    // Show what would be processed
    console.log('\nðŸ“š Opinions Ready for Processing:');
    
    const availableOpinions = await pg.query(`
      SELECT 
        c.case_name,
        o.id as opinion_id,
        o.binding_type
      FROM opinions o
      INNER JOIN cases c ON o.case_id = c.id
      LEFT JOIN opinion_keywords ok ON o.id = ok.opinion_id
      WHERE o.binding_type IN ('015unanimous', '010combined', '020lead')
        AND ok.opinion_id IS NULL
      ORDER BY o.id
      LIMIT $1
    `, [batchSize]);
    
    console.log(`   Found ${availableOpinions.rows.length} opinions ready for keyword extraction:`);
    availableOpinions.rows.slice(0, 5).forEach((row, index) => {
      console.log(`   ${index + 1}. Opinion ${row.opinion_id}: ${row.case_name.substring(0, 60)}...`);
    });
    
    if (availableOpinions.rows.length > 5) {
      console.log(`   ... and ${availableOpinions.rows.length - 5} more opinions`);
    }
    
    // Parallel processing simulation
    console.log('\nâš¡ Parallel Processing Simulation:');
    console.log(`   With ${concurrency} workers processing ${availableOpinions.rows.length} opinions:`);
    
    const estimatedTimePerOpinion = 15; // seconds (conservative estimate)
    const serialTime = availableOpinions.rows.length * estimatedTimePerOpinion;
    const parallelTime = Math.ceil(availableOpinions.rows.length / concurrency) * estimatedTimePerOpinion;
    const timeSaved = serialTime - parallelTime;
    
    console.log(`   â€¢ Serial processing time: ~${Math.round(serialTime / 60)} minutes`);
    console.log(`   â€¢ Parallel processing time: ~${Math.round(parallelTime / 60)} minutes`);
    console.log(`   â€¢ Time saved: ~${Math.round(timeSaved / 60)} minutes (${Math.round(timeSaved / serialTime * 100)}% faster)`);
    
    // Duplicate prevention benefits
    console.log('\nðŸ”„ Duplicate Prevention Benefits:');
    console.log('   â€¢ In-memory tracking prevents processing the same opinion twice');
    console.log('   â€¢ Database checks prevent duplicate keyword insertion');
    console.log('   â€¢ Parallel workers coordinate to avoid conflicts');
    console.log('   â€¢ Graceful handling of race conditions');
    
    // Recommendations
    console.log('\nðŸ’¡ Recommendations:');
    
    if (availableOpinions.rows.length === 0) {
      console.log('   âœ… All opinions already have keywords - system is up to date!');
    } else if (availableOpinions.rows.length < 50) {
      console.log(`   ðŸš€ Ready to process ${availableOpinions.rows.length} opinions`);
      console.log(`   ðŸ’» Suggested command: node batchKeywordExtraction.js ${availableOpinions.rows.length} ${Math.min(concurrency, 3)}`);
    } else {
      console.log(`   ðŸ“ˆ Large batch available (${availableOpinions.rows.length} opinions)`);
      console.log('   ðŸŽ¯ Consider processing in smaller batches first (20-50 opinions)');
      console.log(`   ðŸ’» Suggested command: node batchKeywordExtraction.js 50 ${Math.min(concurrency, 4)}`);
    }
    
    console.log('\nðŸ”§ Enhanced Features:');
    console.log('   â€¢ Parallel processing with configurable workers');
    console.log('   â€¢ Duplicate prevention at multiple levels');
    console.log('   â€¢ Real-time progress tracking with duplicate counts');
    console.log('   â€¢ Quality assessment and OCR artifact handling');
    console.log('   â€¢ Robust error handling and retry logic');
    
  } catch (error) {
    console.error('âŒ Test failed:', error.message);
  } finally {
    await pg.end();
  }
}

// Run the test
testParallelProcessing().catch(console.error);
